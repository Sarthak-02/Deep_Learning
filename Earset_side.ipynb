import os
import numpy as np
from scipy.misc import imread,imsave,imresize,toimage
from PIL import Image
import pickle
import cv2


count=0
x = []
parent_list = os.listdir("/Users/sarthakgupta/Desktop/awe")
for parent in parent_list:
    if parent != '.DS_Store' and parent!='txt':
        #print(parent)
        child_list = os.listdir("/Users/sarthakgupta/Desktop/awe/"+parent)
        for child in child_list:
            if child != 'annotations.json' and child != '.DS_Store':
                count+=1
                image = cv2.imread("/Users/sarthakgupta/Desktop/awe/"+parent+"/"+child)
                image=cv2.resize(image,(96,96))
                x.append(image)              
#print(count)             


import json
count=0
y_gender = []
y_ethnicity = []
y_accessories = []
y_overlap = []
y_hpitch = []
y_hyaw = []
y_version = []
y_hroll = []
y_side = []

json1 = [ "01","02","03","04","05","06","07","08","09","10" ]
parent_list = os.listdir("/Users/sarthakgupta/Desktop/awe")
for parent in parent_list:
    if parent != '.DS_Store' and parent!='txt':
        #print(parent)
        child_list = os.listdir("/Users/sarthakgupta/Desktop/awe/"+parent)
        for child in child_list:
            if child == 'annotations.json':
                with open("/Users/sarthakgupta/Desktop/awe/"+parent+"/"+child) as data_file:    
                    data = json.load(data_file)
                if(data["gender"] == 'm'):
                    choice = 1
                else:
                    choice = 0
                
                for i in range(10):
                    if(data["data"][json1[i]]["d"] == 'l'):
                        left = 1
                    else:
                        left = 0
                    y_gender.append(choice)
                    y_ethnicity.append(data["ethnicity"])
                    y_side.append(left)
                    y_accessories.append(data["data"][json1[i]]["accessories"])
                    y_overlap.append(data["data"][json1[i]]["overlap"])
                    y_hpitch.append(data["data"][json1[i]]["hPitch"])
                    y_hyaw.append(data["data"][json1[i]]["hYaw"])
                    y_version.append(data["data"][json1[i]]["version"])
                    y_hroll.append(data["data"][json1[i]]["hRoll"])
                    #print("gender",choice,"ethnicity",data["ethnicity"],"accessories",data["data"][json1[i]]["accessories"],"overlap",data["data"][json1[i]]["overlap"],"hpitch",data["data"][json1[i]]["hPitch"])
                    #print(y_side)
                
                
                
                              
#print(count)             



from collections import Counter
#Counter(y_ethnicity)
Counter(y_hpitch)


def onehotencoder(y):
    from sklearn.preprocessing import MultiLabelBinarizer
    y_labels=MultiLabelBinarizer().fit_transform(y.reshape(-1, 1)) 
    return y_labels

def shuffle(x,y):
    import random
    train = list(zip(x,y))
    random.shuffle(train)
    x,y = zip(*train)
    
    x = np.array(x)
    y = np.array(y)
    return x,y

def split(x,y):
    x_train,x_test,y_train,y_test = x[:800],x[800:],y[:800],y[800:]
    return x_train,x_test,y_train,y_test
    

x_side,y_side = shuffle(x,y_side)
x_gender,y_gender = shuffle(x,y_gender)
x_ethnicity,y_ethnicity = shuffle(x,y_ethnicity)
x_accessories,y_accessories = shuffle(x,y_accessories)
x_overlap,y_overlap = shuffle(x,y_overlap)
x_hpitch,y_hpitch = shuffle(x,y_hpitch)
x_hroll,y_hroll = shuffle(x,y_hroll)

y_side = onehotencoder(y_side)
y_gender = onehotencoder(y_gender)
y_ethnicity = onehotencoder(y_ethnicity)
y_accessories = onehotencoder(y_accessories)
y_overlap = onehotencoder(y_overlap)
y_hpitch = onehotencoder(y_hpitch)
y_hroll = onehotencoder(y_hroll)

x_side_train,x_side_test,y_side_train,y_side_test = split(x_side,y_side)
x_gender_train,x_gender_test,y_gender_train,y_gender_test = split(x_gender,y_gender)
x_ethnicity_train,x_ethnicity_test,y_ethnicity_train,y_ethnicity_test = split(x_ethnicity,y_ethnicity)
x_accessories_train,x_accessories_test,y_accessories_train,y_accessories_test = split(x_accessories,y_accessories)
x_overlap_train,x_overlap_test,y_overlap_train,y_overlap_test = split(x_overlap,y_overlap)
x_hpitch_train,x_hpitch_test,y_hpitch_train,y_hpitch_test = split(x_hpitch,y_hpitch)
x_hroll_train,x_hroll_test,y_hroll_train,y_hroll_test = split(x_hroll,y_hroll)

d_train={}
d_train['x_side_train']=x_side_train
d_train['x_gender_train']=x_gender_train
d_train['x_ethnicity_train']=x_ethnicity_train
d_train['x_accessories_train']=x_accessories_train
d_train['x_overlap_train']=x_overlap_train
d_train['x_hpitch_train']=x_hpitch_train
d_train['x_hroll_train']=x_hroll_train

d_train['y_side_train']=y_side_train
d_train['y_gender_train']=y_gender_train
d_train['y_ethnicity_train']=y_ethnicity_train
d_train['y_accessories_train']=y_accessories_train
d_train['y_overlap_train']=y_overlap_train
d_train['y_hpitch_train']=y_hpitch_train
d_train['y_hroll_train']=y_hroll_train

with open('train_800.p','wb') as f:
    pickle.dump(d_train,f)
    
d_test={}
d_test['x_side_test']=x_side_test
d_test['x_gender_test']=x_gender_test
d_test['x_ethnicity_test']=x_ethnicity_test
d_test['x_accessories_test']=x_accessories_test
d_test['x_overlap_test']=x_overlap_test
d_test['x_hpitch_test']=x_hpitch_test
d_test['x_hroll_test']=x_hroll_test

d_test['y_side_test']=y_side_test
d_test['y_gender_test']=y_gender_test
d_test['y_ethnicity_test']=y_ethnicity_test
d_test['y_accessories_test']=y_accessories_test
d_test['y_overlap_test']=y_overlap_test
d_test['y_hpitch_test']=y_hpitch_test
d_test['y_hroll_test']=y_hroll_test

with open('test_800.p','wb') as f:
    pickle.dump(d_test,f)
    
    
    import pickle
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD
import numpy as np

train = {}

with open('train_800.p','rb') as f:
    train=pickle.load(f)

x_train,y_train=train['x_side_train'],train['y_side_train']
print(x_train.shape,y_train.shape)
print(y_train[5])

batch_size = 30
nb_classes = 2
nb_epoch = 50

x_train = x_train.astype('float32')
x_train /= 255.0

print(x_train[0])
print(x_train.shape, 'train samples')
print(y_train.shape, 'train sample labels')

test = {}

with open('test_800.p','rb') as f:
    test=pickle.load(f)

x_test,y_test=test['x_side_test'],test['y_side_test']
print(x_test.shape,y_test.shape)

model = Sequential()
model.add(Convolution2D(96,3,3 ,activation='relu',input_shape=(96,96,3)))
model.add(Convolution2D(96,3,3,activation='relu'))
model.add(MaxPooling2D((3,3), strides=(2,2)))
model.add(Convolution2D(192,3,3,activation='relu'))
model.add(Convolution2D(192,3,3,activation='relu'))
model.add(Convolution2D(192,3,3,activation='relu'))
model.add(MaxPooling2D((3,3), strides=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2,activation='softmax'))
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.fit(x_train,y_train,validation_split = 0.2,batch_size=30,nb_epoch=50,verbose=1)



scores = model.evaluate(x_train,y_train, verbose=0)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

scores = model.evaluate(x_test,y_test, verbose=0)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
